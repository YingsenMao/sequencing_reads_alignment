{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGenome(filename):\n",
    "    '''\n",
    "    Reads the reference genome\n",
    "    '''\n",
    "    genome=''\n",
    "    with open(filename,'r') as f:\n",
    "        for line in f:\n",
    "            if not line[0] == '>':\n",
    "                genome += line.rstrip()\n",
    "    return genome\n",
    "\n",
    "genome = readGenome('chr1.GRCh38.excerpt.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TTGAATGCTGAAATCAGCAGGTAATATATG'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive(read, genome):\n",
    "    match = True\n",
    "    alignment = 0\n",
    "    comparison = 0\n",
    "    match_list = []\n",
    "    for i in range(len(genome) - len(read) + 1):\n",
    "        alignment += 1\n",
    "        for j in range(len(read)):\n",
    "            comparison += 1\n",
    "            if not read[j] == genome[i + j]:\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            match_list.append(i)\n",
    "    return match_list, alignment, comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_list, alignment, comparison = naive('GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG', genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 799954 984143\n"
     ]
    }
   ],
   "source": [
    "print(match_list, alignment, comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(genome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def z_array(s):\n",
    "    \"\"\" Use Z algorithm (Gusfield theorem 1.4.1) to preprocess s \"\"\"\n",
    "    assert len(s) > 1\n",
    "    z = [len(s)] + [0] * (len(s)-1)\n",
    "    # Initial comparison of s[1:] with prefix\n",
    "    for i in range(1, len(s)):\n",
    "        if s[i] == s[i-1]:\n",
    "            z[1] += 1\n",
    "        else:\n",
    "            break\n",
    "    r, l = 0, 0\n",
    "    if z[1] > 0:\n",
    "        r, l = z[1], 1\n",
    "    for k in range(2, len(s)):\n",
    "        assert z[k] == 0\n",
    "        if k > r:\n",
    "            # Case 1\n",
    "            for i in range(k, len(s)):\n",
    "                if s[i] == s[i-k]:\n",
    "                    z[k] += 1\n",
    "                else:\n",
    "                    break\n",
    "            r, l = k + z[k] - 1, k\n",
    "        else:\n",
    "            # Case 2\n",
    "            # Calculate length of beta\n",
    "            nbeta = r - k + 1\n",
    "            zkp = z[k - l]\n",
    "            if nbeta > zkp:\n",
    "                # Case 2a: Zkp wins\n",
    "                z[k] = zkp\n",
    "            else:\n",
    "                # Case 2b: Compare characters just past r\n",
    "                nmatch = 0\n",
    "                for i in range(r+1, len(s)):\n",
    "                    if s[i] == s[i - k]:\n",
    "                        nmatch += 1\n",
    "                    else:\n",
    "                        break\n",
    "                l, r = k, r + nmatch\n",
    "                z[k] = r - k + 1\n",
    "    return z\n",
    "\n",
    "\n",
    "def n_array(s):\n",
    "    \"\"\" Compile the N array (Gusfield theorem 2.2.2) from the Z array \"\"\"\n",
    "    return z_array(s[::-1])[::-1]\n",
    "\n",
    "\n",
    "def big_l_prime_array(p, n):\n",
    "    \"\"\" Compile L' array (Gusfield theorem 2.2.2) using p and N array.\n",
    "        L'[i] = largest index j less than n such that N[j] = |P[i:]| \"\"\"\n",
    "    lp = [0] * len(p)\n",
    "    for j in range(len(p)-1):\n",
    "        i = len(p) - n[j]\n",
    "        if i < len(p):\n",
    "            lp[i] = j + 1\n",
    "    return lp\n",
    "\n",
    "\n",
    "def big_l_array(p, lp):\n",
    "    \"\"\" Compile L array (Gusfield theorem 2.2.2) using p and L' array.\n",
    "        L[i] = largest index j less than n such that N[j] >= |P[i:]| \"\"\"\n",
    "    l = [0] * len(p)\n",
    "    l[1] = lp[1]\n",
    "    for i in range(2, len(p)):\n",
    "        l[i] = max(l[i-1], lp[i])\n",
    "    return l\n",
    "\n",
    "\n",
    "def small_l_prime_array(n):\n",
    "    \"\"\" Compile lp' array (Gusfield theorem 2.2.4) using N array. \"\"\"\n",
    "    small_lp = [0] * len(n)\n",
    "    for i in range(len(n)):\n",
    "        if n[i] == i+1:  # prefix matching a suffix\n",
    "            small_lp[len(n)-i-1] = i+1\n",
    "    for i in range(len(n)-2, -1, -1):  # \"smear\" them out to the left\n",
    "        if small_lp[i] == 0:\n",
    "            small_lp[i] = small_lp[i+1]\n",
    "    return small_lp\n",
    "\n",
    "\n",
    "def good_suffix_table(p):\n",
    "    \"\"\" Return tables needed to apply good suffix rule. \"\"\"\n",
    "    n = n_array(p)\n",
    "    lp = big_l_prime_array(p, n)\n",
    "    return lp, big_l_array(p, lp), small_l_prime_array(n)\n",
    "\n",
    "\n",
    "def good_suffix_mismatch(i, big_l_prime, small_l_prime):\n",
    "    \"\"\" Given a mismatch at offset i, and given L/L' and l' arrays,\n",
    "        return amount to shift as determined by good suffix rule. \"\"\"\n",
    "    length = len(big_l_prime)\n",
    "    assert i < length\n",
    "    if i == length - 1:\n",
    "        return 0\n",
    "    i += 1  # i points to leftmost matching position of P\n",
    "    if big_l_prime[i] > 0:\n",
    "        return length - big_l_prime[i]\n",
    "    return length - small_l_prime[i]\n",
    "\n",
    "\n",
    "def good_suffix_match(small_l_prime):\n",
    "    \"\"\" Given a full match of P to T, return amount to shift as\n",
    "        determined by good suffix rule. \"\"\"\n",
    "    return len(small_l_prime) - small_l_prime[1]\n",
    "\n",
    "\n",
    "def dense_bad_char_tab(p, amap):\n",
    "    \"\"\" Given pattern string and list with ordered alphabet characters, create\n",
    "        and return a dense bad character table.  Table is indexed by offset\n",
    "        then by character. \"\"\"\n",
    "    tab = []\n",
    "    nxt = [0] * len(amap)\n",
    "    for i in range(0, len(p)):\n",
    "        c = p[i]\n",
    "        assert c in amap\n",
    "        tab.append(nxt[:])\n",
    "        nxt[amap[c]] = i+1\n",
    "    return tab\n",
    "\n",
    "\n",
    "class BoyerMoore(object):\n",
    "    \"\"\" Encapsulates pattern and associated Boyer-Moore preprocessing. \"\"\"\n",
    "    \n",
    "    def __init__(self, p, alphabet='ACGT'):\n",
    "        self.p = p\n",
    "        self.alphabet = alphabet\n",
    "        # Create map from alphabet characters to integers\n",
    "        self.amap = {}\n",
    "        for i in range(len(self.alphabet)):\n",
    "            self.amap[self.alphabet[i]] = i\n",
    "        # Make bad character rule table\n",
    "        self.bad_char = dense_bad_char_tab(p, self.amap)\n",
    "        # Create good suffix rule table\n",
    "        _, self.big_l, self.small_l_prime = good_suffix_table(p)\n",
    "    \n",
    "    def bad_character_rule(self, i, c):\n",
    "        \"\"\" Return # skips given by bad character rule at offset i \"\"\"\n",
    "        assert c in self.amap\n",
    "        ci = self.amap[c]\n",
    "        assert i > (self.bad_char[i][ci]-1)\n",
    "        return i - (self.bad_char[i][ci]-1)\n",
    "    \n",
    "    def good_suffix_rule(self, i):\n",
    "        \"\"\" Given a mismatch at offset i, return amount to shift\n",
    "            as determined by (weak) good suffix rule. \"\"\"\n",
    "        length = len(self.big_l)\n",
    "        assert i < length\n",
    "        if i == length - 1:\n",
    "            return 0\n",
    "        i += 1  # i points to leftmost matching position of P\n",
    "        if self.big_l[i] > 0:\n",
    "            return length - self.big_l[i]\n",
    "        return length - self.small_l_prime[i]\n",
    "    \n",
    "    def match_skip(self):\n",
    "        \"\"\" Return amount to shift in case where P matches T \"\"\"\n",
    "        return len(self.small_l_prime) - self.small_l_prime[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boyer_moore(p, p_bm, t):\n",
    "    occurence = []\n",
    "    alignment_total = 0\n",
    "    i = 0\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        alignment_total += 1\n",
    "        shift = 1\n",
    "        match = True\n",
    "        for j in range(len(p) - 1, -1, -1):\n",
    "            if not t[i + j] == p[j]:\n",
    "                gs = p_bm.good_suffix_rule(j)\n",
    "                bd = p_bm.bad_character_rule(j, t[i+j])\n",
    "                match = False\n",
    "                shift = max(gs, bd, shift)\n",
    "                break\n",
    "        if match:\n",
    "            ms = p_bm.match_skip()\n",
    "            shift = max(ms, shift)\n",
    "            occurence.append(i)\n",
    "        i += shift\n",
    "    return occurence, alignment_total\n",
    "\n",
    "t = 'GCTAGA'\n",
    "p = 'TCTA'\n",
    "p_bm = BoyerMoore(p, alphabet='ACGT')\n",
    "occurence, alignments = boyer_moore(p, p_bm, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922]\n"
     ]
    }
   ],
   "source": [
    "def boyer_moore(p, p_bm, t):\n",
    "    \"\"\" Do Boyer-Moore matching \"\"\"\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    # (len(t) - len(p) + 1) is the maximum number of possible alignments\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        # try character comparison BACKWARDS\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                # once mismatch occurs, record the number of shifts before break\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurrences\n",
    "\n",
    "read = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "p_bm = BoyerMoore(read, alphabet='ACGT')\n",
    "occurence = boyer_moore(read, p_bm, genome)\n",
    "print(occurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'GCTAGA'\n",
    "'TCTA'\n",
    "  'TCTA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 1\n"
     ]
    }
   ],
   "source": [
    "print(occurence,alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922] 127974\n"
     ]
    }
   ],
   "source": [
    "read = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "p_bm = BoyerMoore(read, alphabet='ACGT')\n",
    "occurence, alignments = boyer_moore(read, p_bm, genome)\n",
    "print(occurence,alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "class Index(object):\n",
    "    \"\"\" Holds a substring index for a text T \"\"\"\n",
    "    def __init__(self, t, k):\n",
    "        \"\"\" Create index from all substrings of t of length k \"\"\"\n",
    "        self.t = t\n",
    "        self.k = k  # k-mer length (k)\n",
    "        self.index = []\n",
    "        for i in range(len(t) - k + 1):  # for each k-mer\n",
    "            self.index.append((t[i:i+k], i))  # add (k-mer, offset) pair\n",
    "        self.index.sort()  # alphabetize by k-mer\n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first k-mer of p \"\"\"\n",
    "        kmer = p[:self.k]  # query with first k-mer\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != kmer:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 15]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def queryIndex(p, t, index_obj):\n",
    "    k = index_obj.k\n",
    "    hits_list = index_obj.query(p)\n",
    "    offset = []\n",
    "    for i in hits_list:\n",
    "        if p[k:] == t[i + k: i + len(p)]:\n",
    "            offset.append(i)\n",
    "    return offset\n",
    "\n",
    "text = 'wegdsatesdsafdsate'\n",
    "pattern = 'ate'\n",
    "index_obj = Index(text, 2)\n",
    "queryIndex(pattern, text, index_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fs'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= 'sdfsa'\n",
    "test[1+1:2+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(56922, 0),\n",
       " (84641, 1),\n",
       " (147558, 1),\n",
       " (160162, 2),\n",
       " (160729, 1),\n",
       " (191452, 1),\n",
       " (262042, 0),\n",
       " (273669, 1),\n",
       " (364263, 0),\n",
       " (421221, 2),\n",
       " (429299, 1),\n",
       " (465647, 1),\n",
       " (551134, 2),\n",
       " (635931, 2),\n",
       " (657496, 0),\n",
       " (681737, 1),\n",
       " (717706, 0),\n",
       " (724927, 1),\n",
       " (747359, 2)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bisect\n",
    "\n",
    "class pigeonhole_kmer(object):\n",
    "    \"\"\" Holds a substring index for a text T \"\"\"\n",
    "    def __init__(self, t, k, p, m):\n",
    "        \"\"\" Create index from all substrings of t of length k \"\"\"\n",
    "        self.t = t\n",
    "        self.k = k  # k-mer length (k)\n",
    "        self.p = p\n",
    "        self.m = m\n",
    "        self.index = []\n",
    "        for i in range(len(t) - k + 1):  # for each k-mer\n",
    "            self.index.append((t[i:i+k], i))  # add (k-mer, offset) pair\n",
    "        self.index.sort()  # alphabetize by k-mer\n",
    "        \n",
    "    def kmerQuery(self, p_sec):\n",
    "        \"\"\" Return index hits for first k-mer of p \"\"\"\n",
    "        kmer = p_sec[:self.k]  # query with first k-mer\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != kmer:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "            \n",
    "        offset = []\n",
    "        for i in hits:\n",
    "            if p_sec[self.k:] == t[i + self.k: i + len(p_sec)]:\n",
    "                offset.append(i)\n",
    "        return offset\n",
    "\n",
    "    def pigeonhole(self):\n",
    "        p_section_n = self.m + 1\n",
    "        p_section_l = round(len(self.p) / p_section_n)\n",
    "        occurence = []\n",
    "        for i in range(p_section_n):\n",
    "            start = i * p_section_l\n",
    "            end = min((i + 1) * p_section_l, len(self.p))\n",
    "            p_section = self.p[start:end]\n",
    "            matches = self.kmerQuery(p_section)\n",
    "            \n",
    "            for m in matches:\n",
    "                mismatches = 0\n",
    "                if m < start or m - start + len(p_section) > len(self.t):\n",
    "                    continue\n",
    "                for i in range(0, start):\n",
    "                    if self.p[i] != self.t[m - start + i]:\n",
    "                        mismatches += 1\n",
    "                    if mismatches > self.m:\n",
    "                        break\n",
    "                for j in range(end, len(self.p)):\n",
    "                    if self.p[j] != self.t[m - start + j]:\n",
    "                        mismatches += 1\n",
    "                    if mismatches > self.m:\n",
    "                        break                        \n",
    "                \n",
    "                if mismatches <= self.m:\n",
    "                    occurence.append((m - start, mismatches))\n",
    "                \n",
    "        return occurence\n",
    "    \n",
    "read = 'GGCGCGGTGGCTCACGCCTGTAAT'                        \n",
    "pk = pigeonhole_kmer(genome, 8, read, 2)\n",
    "ls = pk.pigeonhole()\n",
    "ls = list(set(ls))\n",
    "ls.sort(key=lambda tup: tup[0])\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(56922, 0),\n",
       " (84641, 1),\n",
       " (147558, 1),\n",
       " (160162, 2),\n",
       " (160729, 1),\n",
       " (191452, 1),\n",
       " (262042, 0),\n",
       " (273669, 1),\n",
       " (364263, 0),\n",
       " (421221, 2),\n",
       " (429299, 1),\n",
       " (465647, 1),\n",
       " (551134, 2),\n",
       " (635931, 2),\n",
       " (657496, 0),\n",
       " (681737, 1),\n",
       " (717706, 0),\n",
       " (724927, 1),\n",
       " (747359, 2)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class naive_ap(object):\n",
    "    def __init__(self, p, t, m):\n",
    "        self.p = p\n",
    "        self.t = t\n",
    "        self.m = m\n",
    "        \n",
    "    def naive(self):\n",
    "        occurence = []\n",
    "        for i in range(len(self.t) - len(self.p) + 1):\n",
    "            match = True\n",
    "            mismatch = 0\n",
    "            for j in range(len(self.p)):\n",
    "                if self.t[i + j ] != self.p[j]:\n",
    "                    mismatch += 1\n",
    "                if mismatch > self.m:\n",
    "                    match = False\n",
    "                    break\n",
    "            if match:\n",
    "                occurence.append((i, mismatch))\n",
    "        return occurence\n",
    "\n",
    "read = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "result = naive_ap(read, genome, 2)\n",
    "result.naive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bisect\n",
    "\n",
    "class hits_pigeonhole_kmer(object):\n",
    "    \"\"\" Holds a substring index for a text T \"\"\"\n",
    "    def __init__(self, t, k, p, m):\n",
    "        \"\"\" Create index from all substrings of t of length k \"\"\"\n",
    "        self.t = t\n",
    "        self.k = k  # k-mer length (k)\n",
    "        self.p = p\n",
    "        self.m = m\n",
    "        self.index = []\n",
    "        for i in range(len(t) - k + 1):  # for each k-mer\n",
    "            self.index.append((t[i:i+k], i))  # add (k-mer, offset) pair\n",
    "        self.index.sort()  # alphabetize by k-mer\n",
    "        \n",
    "    def kmerQuery(self, p_sec):\n",
    "        \"\"\" Return index hits for first k-mer of p \"\"\"\n",
    "        kmer = p_sec[:self.k]  # query with first k-mer\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != kmer:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "            \n",
    "        offset = []\n",
    "        for i in hits:\n",
    "            if p_sec[self.k:] == t[i + self.k: i + len(p_sec)]:\n",
    "                offset.append(i)\n",
    "        return hits, offset\n",
    "\n",
    "    def pigeonhole(self):\n",
    "        p_section_n = self.m + 1\n",
    "        p_section_l = round(len(self.p) / p_section_n)\n",
    "        total_hits = []\n",
    "        for i in range(p_section_n):\n",
    "            start = i * p_section_l\n",
    "            end = min((i + 1) * p_section_l, len(self.p))\n",
    "            p_section = self.p[start:end]\n",
    "            hits, _ = self.kmerQuery(p_section)\n",
    "            total_hits.extend(hits)\n",
    "        return len(total_hits)\n",
    "\n",
    "read = 'GGCGCGGTGGCTCACGCCTGTAAT'                        \n",
    "ht = hits_pigeonhole_kmer(genome, 8, read, 2)\n",
    "ht.pigeonhole()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fasf'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'sfasfdgfsdadfs'\n",
    "test[1:5:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bisect\n",
    "   \n",
    "class SubseqIndex(object):\n",
    "    \"\"\" Holds a subsequence index for a text T \"\"\"\n",
    "    \n",
    "    def __init__(self, t, k, ival):\n",
    "        \"\"\" Create index from all subsequences consisting of k characters\n",
    "            spaced ival positions apart.  E.g., SubseqIndex(\"ATAT\", 2, 2)\n",
    "            extracts (\"AA\", 0) and (\"TT\", 1). \"\"\"\n",
    "        self.k = k  # num characters per subsequence extracted\n",
    "        self.ival = ival  # space between them; 1=adjacent, 2=every other, etc\n",
    "        self.index = []\n",
    "        self.span = 1 + ival * (k - 1)\n",
    "        for i in range(len(t) - self.span + 1):  # for each subseq\n",
    "            self.index.append((t[i:i+self.span:ival], i))  # add (subseq, offset)\n",
    "        self.index.sort()  # alphabetize by subseq\n",
    "    \n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first subseq of p \"\"\"\n",
    "        subseq = p[:self.span:self.ival]  # query with first subseq\n",
    "        i = bisect.bisect_left(self.index, (subseq, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != subseq:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits\n",
    "\n",
    "read = 'GGCGCGGTGGCTCACGCCTGTAAT' \n",
    "si = SubseqIndex(genome, 8, 3)\n",
    "len(si.query(read))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
